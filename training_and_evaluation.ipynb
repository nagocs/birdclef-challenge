{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nagocs/birdclef-challenge/blob/main/training_and_evaluation.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2vLa7pm3OX4",
        "outputId": "2310ac12-3cd8-405f-d921-dbdf3b2e5d51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Letöltés...\n",
            "/usr/local/lib/python3.12/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1cxXQ1E-a3Rw0GMEeq0Vaq_3ZvN-dsumN\n",
            "From (redirected): https://drive.google.com/uc?id=1cxXQ1E-a3Rw0GMEeq0Vaq_3ZvN-dsumN&confirm=t&uuid=b4def99b-a8b0-437c-acea-269aa380c1b1\n",
            "To: /content/train_audio.zip\n",
            "100% 7.78G/7.78G [01:37<00:00, 79.5MB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ylq0SPuidYMHV3JqL3LV12zyf2Bp6WrN\n",
            "To: /content/train_metadata.csv\n",
            "100% 5.13M/5.13M [00:00<00:00, 175MB/s]\n",
            "Letöltés kész!\n",
            "\n",
            "Fájlméretek:\n",
            "-rw-r--r-- 1 root root 7.3G Nov 27 10:16 train_audio.zip\n",
            "-rw-r--r-- 1 root root 4.9M Nov  1 18:38 train_metadata.csv\n",
            "\n",
            "Kicsomagolás...\n",
            "Kész! A dataset a 'train_audio/' és 'train_metadata.csv' helyeken található.\n"
          ]
        }
      ],
      "source": [
        "!pip install -q gdown\n",
        "\n",
        "import os\n",
        "\n",
        "print(\"Letöltés...\")\n",
        "\n",
        "# train_audio.zip\n",
        "zip_id = \"1cxXQ1E-a3Rw0GMEeq0Vaq_3ZvN-dsumN\"\n",
        "zip_out = \"train_audio.zip\"\n",
        "\n",
        "# train_metadata.csv\n",
        "csv_id = \"1ylq0SPuidYMHV3JqL3LV12zyf2Bp6WrN\"\n",
        "csv_out = \"train_metadata.csv\"\n",
        "\n",
        "!gdown --id $zip_id -O $zip_out\n",
        "!gdown --id $csv_id -O $csv_out\n",
        "\n",
        "print(\"Letöltés kész!\")\n",
        "\n",
        "print(\"\\nFájlméretek:\")\n",
        "!ls -lh train_audio.zip\n",
        "!ls -lh train_metadata.csv\n",
        "\n",
        "print(\"\\nKicsomagolás...\")\n",
        "os.makedirs(\"train_audio\", exist_ok=True)\n",
        "!unzip -q train_audio.zip -d birdclef_2024\n",
        "\n",
        "print(\"Kész! A dataset a 'birdclef_2024/' és 'train_metadata.csv' helyeken található.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FaUL0HwCAEk",
        "outputId": "4cd893c9-5eca-4907-da7f-6008d86e9ac3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch shape: (32, 256, 384, 1) (32,)\n",
            "Train set: 19567 = 612 batch\n",
            "Validation set: 2446 = 77 batch\n",
            "Test set: 2446 = 77 batch\n",
            "Number of classes: 182\n"
          ]
        }
      ],
      "source": [
        "# ---------------------------------------------------------\n",
        "# 0. Libraries\n",
        "# ---------------------------------------------------------\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 1. CONFIG class\n",
        "# ---------------------------------------------------------\n",
        "class CONFIG:\n",
        "    seed = 42\n",
        "\n",
        "    img_size = [128, 384]\n",
        "    batch_size = 32\n",
        "\n",
        "    duration = 15\n",
        "    sample_rate = 32000\n",
        "    audio_len = duration * sample_rate\n",
        "\n",
        "    nfft = 2028\n",
        "    window = 2048\n",
        "    hop_length = audio_len // (img_size[1] - 1)\n",
        "    fmin = 20\n",
        "    fmax = 16000\n",
        "\n",
        "    augment = True\n",
        "\n",
        "    class_names = sorted(os.listdir('birdclef_2024/train_audio/'))\n",
        "    num_classes = len(class_names)\n",
        "\n",
        "    class_labels = list(range(num_classes))\n",
        "    label2name = dict(zip(class_labels, class_names))\n",
        "    name2label = {v: k for k, v in label2name.items()}\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 2. Metadata\n",
        "# ---------------------------------------------------------\n",
        "df = pd.read_csv(\"train_metadata.csv\")\n",
        "df[\"filepath\"] = \"birdclef_2024/train_audio/\" + df[\"filename\"]\n",
        "df[\"target\"] = df[\"primary_label\"].map(CONFIG.name2label)\n",
        "df['filename'] = df.filepath.map(lambda x: x.split('/')[-1])\n",
        "df[\"xc_id\"] = df[\"filename\"].apply(lambda x: x.split(\"/\")[-1].split(\".\")[0])\n",
        "\n",
        "num_classes = df[\"target\"].nunique()\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 3. Audio file\n",
        "# ---------------------------------------------------------\n",
        "def load_audio(filepath):\n",
        "    audio, sr = librosa.load(filepath, sr=CONFIG.sample_rate)\n",
        "    return audio, sr\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 4. Spectrogram\n",
        "# ---------------------------------------------------------\n",
        "def get_spectrogram(audio):\n",
        "    spec = librosa.feature.melspectrogram(\n",
        "        y=audio,\n",
        "        sr=CONFIG.sample_rate,\n",
        "        n_mels=256,\n",
        "        n_fft=CONFIG.nfft,\n",
        "        hop_length=CONFIG.hop_length,\n",
        "        fmax=CONFIG.fmax,\n",
        "        fmin=CONFIG.fmin,\n",
        "    )\n",
        "\n",
        "    spec = librosa.power_to_db(spec, ref=1.0)\n",
        "\n",
        "    min_db = spec.min()\n",
        "    max_db = spec.max()\n",
        "    if max_db != min_db:\n",
        "        spec = (spec - min_db) / (max_db - min_db)\n",
        "\n",
        "    return spec\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 5. Train / Validation / Test Split\n",
        "# ---------------------------------------------------------\n",
        "train_df, temp_df = train_test_split(\n",
        "    df,\n",
        "    test_size=0.2,\n",
        "    random_state=CONFIG.seed,\n",
        "    stratify=df[\"target\"]\n",
        ")\n",
        "\n",
        "val_df, test_df = train_test_split(\n",
        "    temp_df,\n",
        "    test_size=0.5,\n",
        "    random_state=CONFIG.seed,\n",
        ")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 6. Keras Dataset Generator\n",
        "# ---------------------------------------------------------\n",
        "class KerasAudioDataset(tf.keras.utils.Sequence):\n",
        "\n",
        "    def __init__(self, dataframe, batch_size=32, augment=False, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.df = dataframe.reset_index(drop=True)\n",
        "        self.batch_size = batch_size\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.df) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch_df = self.df.iloc[index*self.batch_size : (index+1)*self.batch_size]\n",
        "\n",
        "        specs = []\n",
        "        labels = []\n",
        "\n",
        "        for _, row in batch_df.iterrows():\n",
        "            audio, sr = load_audio(row.filepath)\n",
        "\n",
        "            if len(audio) < CONFIG.audio_len:\n",
        "                pad_len = CONFIG.audio_len - len(audio)\n",
        "                audio = np.pad(audio, (0, pad_len))\n",
        "            else:\n",
        "                audio = audio[:CONFIG.audio_len]\n",
        "\n",
        "            spec = get_spectrogram(audio)\n",
        "\n",
        "            if self.augment:\n",
        "                spec = self.apply_augment(spec)\n",
        "\n",
        "            spec = np.expand_dims(spec, axis=-1).astype(np.float32)\n",
        "\n",
        "            specs.append(spec)\n",
        "            labels.append(row.target)\n",
        "\n",
        "        return np.array(specs), np.array(labels)\n",
        "\n",
        "    def apply_augment(self, spec):\n",
        "        if np.random.rand() < 0.3:\n",
        "            spec = spec * np.random.uniform(0.7, 1.3)\n",
        "        return spec\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 7. Create training and validation set\n",
        "# ---------------------------------------------------------\n",
        "train_dataset = KerasAudioDataset(\n",
        "    train_df,\n",
        "    batch_size=CONFIG.batch_size,\n",
        "    augment=CONFIG.augment\n",
        ")\n",
        "\n",
        "val_dataset = KerasAudioDataset(\n",
        "    val_df,\n",
        "    batch_size=CONFIG.batch_size,\n",
        "    augment=False\n",
        ")\n",
        "\n",
        "test_dataset = KerasAudioDataset(\n",
        "    test_df,\n",
        "    batch_size=CONFIG.batch_size,\n",
        "    augment=False\n",
        ")\n",
        "\n",
        "X, y = train_dataset[0]\n",
        "print(\"Batch shape:\", X.shape, y.shape)\n",
        "print(\"Train set:\", len(train_df), \"=\", len(train_dataset), \"batch\")\n",
        "print(\"Validation set:\", len(val_df), \"=\", len(val_dataset), \"batch\")\n",
        "print(\"Test set:\", len(test_df), \"=\", len(test_dataset), \"batch\")\n",
        "print(\"Number of classes:\", num_classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPOmsp8MNC3r",
        "outputId": "d6d685c7-49a1-4e04-9eae-df6fc2d49332"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Összes paraméter: 11598934\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "\n",
        "# ----------------------------------------------------\n",
        "#   Fused-MBConv blokk\n",
        "# ----------------------------------------------------\n",
        "def fused_mbconv(x, expand_channels, out_channels, stride):\n",
        "    inp = x\n",
        "\n",
        "    # Expand 3×3 conv (fused: nincs 1×1 expand)\n",
        "    x = layers.Conv2D(expand_channels, 3, stride, padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('swish')(x)\n",
        "\n",
        "    # Projection 1×1\n",
        "    x = layers.Conv2D(out_channels, 1, 1, padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    # Skip connection\n",
        "    if stride == 1 and inp.shape[-1] == out_channels:\n",
        "        x = layers.Add()([x, inp])\n",
        "\n",
        "    return x\n",
        "\n",
        "# ----------------------------------------------------\n",
        "#   MBConv blokk (SE-vel)\n",
        "# ----------------------------------------------------\n",
        "def mbconv(x, expand_channels, out_channels, stride, se_ratio=0.25):\n",
        "    inp = x\n",
        "    inp_channels = x.shape[-1]\n",
        "\n",
        "    # Expand 1×1\n",
        "    x = layers.Conv2D(expand_channels, 1, 1, padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('swish')(x)\n",
        "\n",
        "    # Depthwise conv\n",
        "    x = layers.DepthwiseConv2D(3, stride, padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('swish')(x)\n",
        "\n",
        "    # Squeeze and Excitation\n",
        "    se = layers.GlobalAveragePooling2D()(x)\n",
        "    se = layers.Dense(int(expand_channels * se_ratio), activation='swish')(se)\n",
        "    se = layers.Dense(expand_channels, activation='sigmoid')(se)\n",
        "    se = layers.Reshape((1, 1, expand_channels))(se)\n",
        "    x = layers.Multiply()([x, se])\n",
        "\n",
        "    # Projection 1×1\n",
        "    x = layers.Conv2D(out_channels, 1, 1, padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    # Skip connection\n",
        "    if stride == 1 and inp_channels == out_channels:\n",
        "        x = layers.Add()([x, inp])\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "# ----------------------------------------------------\n",
        "#   EfficientNetV2-B0\n",
        "# ----------------------------------------------------\n",
        "def EfficientNetV2B0(input_shape = X.shape[1:], num_classes=num_classes):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = inputs\n",
        "\n",
        "    # Stem\n",
        "    x = layers.Conv2D(32, 3, 2, padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('swish')(x)\n",
        "\n",
        "    # Stage 1: 2× Fused-MBConv\n",
        "    for _ in range(2):\n",
        "        x = fused_mbconv(x, expand_channels=32, out_channels=16, stride=1)\n",
        "\n",
        "    # Stage 2: 4× Fused-MBConv, stride=2 at first\n",
        "    for i in range(4):\n",
        "        x = fused_mbconv(x, expand_channels=64, out_channels=32, stride=2 if i == 0 else 1)\n",
        "\n",
        "    # Stage 3: 4× Fused-MBConv\n",
        "    for i in range(4):\n",
        "        x = fused_mbconv(x, expand_channels=96, out_channels=48, stride=2 if i == 0 else 1)\n",
        "\n",
        "    # Stage 4: 6× MBConv\n",
        "    for i in range(6):\n",
        "        x = mbconv(x, expand_channels=192, out_channels=96, stride=2 if i == 0 else 1)\n",
        "\n",
        "    # Stage 5: 9× MBConv\n",
        "    for i in range(9):\n",
        "        x = mbconv(x, expand_channels=384, out_channels=112, stride=1)\n",
        "\n",
        "    # Stage 6: 15× MBConv\n",
        "    for i in range(15):\n",
        "        x = mbconv(x, expand_channels=768, out_channels=192, stride=2 if i == 0 else 1)\n",
        "\n",
        "    # Head\n",
        "    x = layers.Conv2D(1280, 1, 1, padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('swish')(x)\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    return Model(inputs, x)\n",
        "\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# Példa használatra:\n",
        "# ----------------------------------------------------\n",
        "model = EfficientNetV2B0()\n",
        "#model.summary()\n",
        "total_params = model.count_params()\n",
        "print(\"Összes paraméter:\", total_params)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAq_23dEOsYx"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint(\"best_cnn.keras\", save_best_only=True, monitor=\"val_loss\"),\n",
        "    EarlyStopping(patience=5, restore_best_weights=True)\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=10,\n",
        "    callbacks=callbacks\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09dd6a02"
      },
      "outputs": [],
      "source": [
        "# ----------------------------------------------------\n",
        "# Kiértékelés\n",
        "# ----------------------------------------------------\n",
        "\n",
        "model = tf.keras.models.load_model(\"best_cnn.keras\")\n",
        "\n",
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
